---
title: 计算机系统基本概念
date: 2023-12-11
author: 王兵
summary: 计算机系统基本概念，计算机硬件和软件的基础。
tag:
  - 制作一个CPU
  - 计算机架构
  - 硬件与软件基础
  - 数据传输方法
---

标签：[制作一个CPU](../../_tags/制作一个CPU), [计算机架构](../../_tags/计算机架构), [硬件与软件基础](../../_tags/硬件与软件基础), [数据传输方法](../../_tags/数据传输方法)

## 1. CPU

### 1.1 CPU 的基本结构

+ **控制单元（CU）**：解释程序指令，并控制其他部件以执行这些指令。
+ **算术逻辑单元（ALU）**：执行所有的算术和逻辑运算。
+ **寄存器**：用于临时存储数据和指令。
+ **总线**：连接 CPU 的不同部分，并与内存和其他硬件组件通信。

### 1.2 指令执行

+ **取指令（Fetch）**：CPU 从内存中读取指令，通常存储在程序计数器（PC）指向的地址中。
+ **解码（Decode）**：控制单元解码取出的指令，确定需要执行的操作和所需的操作数。
+ **执行（Execute）**：ALU 根据解码的指令执行算术或逻辑运算。

### 1.3. 数据处理

+ **数据运算**：ALU 根据执行阶段的指令对数据进行算术或逻辑运算。
+ **数据访问**：CPU 通过数据总线与内存或输入/输出设备交换数据。

### 1.4. 控制流

+ **顺序执行**：大多数时候，CPU 按照指令在内存中的顺序执行。
+ **分支和跳转**：某些指令会更改程序计数器的值，导致 CPU 跳转到程序中的不同部分执行。
+ **循环和条件执行**：CPU 可以根据特定条件重复执行一组指令，或者根据条件判断是否执行某个指令块。

### 1.5. 现代 CPU 特性

+ **流水线（Pipelining）**：将指令执行过程分为多个阶段，每个阶段同时处理不同的指令，提高效率。
+ **超标量架构**：允许 CPU 在一个时钟周期内同时执行多个指令。
+ **缓存记忆体**：减少访问主内存的次数，提高处理速度。

### 1.6. 并行处理

+ **多线程**：一颗 CPU 能够同时处理多个线程，提高执行效率。
+ **多核心**：现代 CPU 通常包含多个独立的核心，每个核心可以同时执行不同的任务。


## 2. 存储器

### 2.1. 随机访问存储器（RAM）

- **特点**：RAM 是一种可读写的存储器，可以随机访问任何存储位置，速度快，但是断电后数据会丢失（易失性）。
- **角色**：
    - **主存储器**：RAM 通常作为主存储器，存储正在运行的程序和当前使用的数据。
    - **快速访问**：由于 RAM 的访问速度远快于硬盘等非易失性存储器，它用于存储那些需要频繁访问或临时修改的数据。
    - **多任务处理**：RAM 的容量影响计算机同时处理多个任务的能力。

### 2.2. 只读存储器（ROM）

- **特点**：ROM 是一种只能读取的存储器，存储的数据通常在制造时写入，断电后数据不会丢失（非易失性）。
- **角色**：
    - **固件存储**：存储固件和计算机启动时的引导程序（如 BIOS）。
    - **系统稳定性**：由于存储在 ROM 中的数据不易更改，它为计算机系统提供了稳定的启动和运行环境。

### 2.3. 缓存（Cache）

- **特点**：缓存是一种高速存储器，用于临时存储 CPU 最近访问的数据和指令，速度通常比 RAM 快，但容量较小。
- **角色**：
    - **减少访问延迟**：缓存通过存储最近或频繁使用的数据，减少了 CPU 与主存（RAM）之间的访问时间。
    - **提高处理速度**：缓存可以显著提高数据处理速度，因为 CPU 可以更快地获取到需要的数据。
    - **多级缓存**：现代计算机通常拥有多级缓存（如 L1、L2、L3 缓存），每级缓存的速度和大小都有所不同，旨在优化数据访问效率。

### 2.4. 比较存储器读写速度

| 存储类型      | 读取速度（大致范围） | 写入速度（大致范围） | 备注                                   |
|-----------| -------------------- | -------------------- | -------------------------------------- |
| RAM       | 15-25 GB/s           | 10-20 GB/s           | 随机访问存储器，用于活动数据和程序     |
| ROM       | 50-100 MB/s          | 通常不适用           | 只读存储器，用于固件等                 |
| Cache     | 200-300 GB/s         | 200-300 GB/s         | CPU 内置，用于存储频繁访问的数据和指令 |
| HDD       | 80-160 MB/s          | 70-150 MB/s          | 机械硬盘，速度受磁盘转速等因素影响     |
| SSD（SATA） | 200-550 MB/s（SATA） | 200-500 MB/s（SATA） | 固态硬盘，速度较快但低于 RAM 和 Cache  |
| SSD（NVMe） | 1-3 GB/s（NVMe）     | 1-3 GB/s（NVMe）     | NVMe 接口的 SSD 速度更快               |
| 300兆宽带    | 约 37.5 MB/s         | 约 37.5 MB/s         | 网络速度，300 Mbps 等于约 37.5 MB/s    |
| 千兆宽带      | 约 125 MB/s          | 约 125 MB/s          | 网络速度，1000 Mbps 等于约 125 MB/s    |

### 2.5. Cache 多级缓存

| 缓存层级 | 读写速度（大致范围） | 功能                                                       | 大小范围        |
| -------- | -------------------- | ---------------------------------------------------------- | --------------- |
| L1 缓存  | 约 0.5 - 1 ns        | 提供最快速的数据访问，减少延迟；直接与 CPU 核心集成        | 几十到几百 KB   |
| L2 缓存  | 约 1 - 5 ns          | 平衡速度和存储容量；可能每核心独立或多核心共享             | 几百 KB 到几 MB |
| L3 缓存  | 约 10 - 30 ns        | 减少对主内存的访问次数；在多核处理器中，通常由所有核心共享 | 几 MB 到几十 MB |

## 3. 输入/输出系统（I/O）

输入输出系统（I/O系统）是计算机架构中的关键组成部分，负责管理外部设备与 CPU 和内存之间的数据交互。I/O系统的设计关键在于有效地管理数据流，确保数据在计算机内部和外部设备之间高效、准确地传输，同时最小化对CPU性能的影响。

### 3.1. I/O系统的主要组件

+ **外部设备**：包括键盘、鼠标、打印机、显示器、硬盘驱动器等。
+ **I/O端口**：用于连接外部设备和计算机系统。
+ **I/O控制器**：为特定类型的外部设备提供控制和定时功能。
+ **总线**：连接不同设备和计算机系统内部组件的数据通道。

### 3.2. 外部设备与 CPU、内存的数据传输方法

+ **程序控制I/O**：CPU 直接控制数据传输，适用于低速设备，因为产生的数据不会很多，这样不会过多占用 CPU 资源，比如简单的的 LED 指示灯，设计比较简单，减少系统成本和设计复杂度。
+ **中断驱动I/O**：当设备准备好数据时，会发送中断信号给 CPU，减少 CPU 等待时间。如果不中断 CPU，那么 CPU 为了知道各种外设的数据需求，将不得不轮询设备浪费时间。侧重与不连续、间歇性的数据传输，CPU 仍然需要处理数据。
+ **直接内存访问（DMA）**：允许外部设备直接与内存交换数据，无需 CPU 干预，适用于高速数据传输。

### 3.3. 中断驱动I/O 和 直接内存访问（DMA）的过程比较

3.3.1. **中断驱动 I/O**：
+ **等待中断**：CPU 执行其他任务，直到接收到来自外部设备的中断请求。
+ **中断响应**：CPU 响应中断，保存当前任务的状态，并执行中断服务程序。
+ **数据处理**：CPU 直接从 I/O 设备读取或向其写入数据，处理相关任务。
+ **任务恢复**：完成数据处理后，CPU 恢复之前被中断的任务。

3.3.2. **DMA**：
+ **初始化**：DMA 控制器接收到来自外部设备的数据传输请求。
+ **配置**：CPU 设置 DMA 控制器，指定源地址、目标地址和传输的数据量。
+ **数据传输**：DMA 控制器直接管理从源地址到目标地址的数据传输，而无需 CPU 的干预。
+ **中断**：数据传输完成后，DMA 控制器发送中断信号给 CPU，告知完成状态。
+ **结束处理**：CPU 响应中断，可能会进行后续处理，如检查数据完整性或更新程序状态。

3.3.3. **异同点**：
| 特性/机制            | 程序控制 I/O                 | 中断驱动 I/O                     | 直接内存访问 (DMA)             |
| -------------------- | ---------------------------- | -------------------------------- | ------------------------------ |
| **CPU 参与程度**     | 高（CPU 直接管理数据传输）   | 中（CPU 在中断时处理数据）       | 低（CPU 仅在开始和结束时参与） |
| **数据处理方式**     | CPU 轮询检查并处理数据       | CPU 响应中断并处理数据           | DMA 控制器管理数据传输         |
| **效率**             | 适用于低速、间歇性的数据传输 | 适用于中等速度、间歇性的数据传输 | 适用于高速、连续的数据传输     |
| **适用场景**         | 低速设备，如简单的传感器     | 间歇性数据，如键盘输入           | 大量数据，如硬盘文件传输       |
| **系统复杂性**       | 相对简单                     | 中等复杂性                       | 相对复杂，需要 DMA 硬件支持    |
| **对系统性能的影响** | 可能导致 CPU 效率低下        | 减少 CPU 轮询，提高效率          | 显著减轻 CPU 负担              |
| **数据传输控制**     | 由 CPU 完全控制              | 由 CPU 在接收中断后控制          | 由 DMA 控制器独立控制          |

### 3.4. 数据传输的基本原理：内存映射

- 3.4.1. **内存映射 I/O**：将一部分内存地址空间分配给 I/O 设备，CPU 通过读写这些内存地址来控制设备。
    - **工作原理**：在内存映射 I/O 中，外部设备的控制寄存器被映射到主内存的地址空间。CPU 通过读写这些内存地址来控制外部设备，就像访问普通内存一样。
    - **优点**：
        - **统一的地址空间**：CPU 可以使用标准的内存访问指令来控制 I/O 设备。
        - **简化编程**：由于使用的是常规的内存访问操作，因此简化了编程模型。
    - **应用场景**：适用于需要大量数据交换的情况，如图形处理等。

- 3.4.2. **I/O 端口映射**：设备有专门的地址空间，CPU 通过特定的 I/O 指令访问这些地址来控制设备。
    - **工作原理**：在 I/O 端口映射中，外部设备有单独的地址空间，与主内存空间分离。CPU 使用专门的 I/O 指令来访问这些地址，从而控制外部设备。
    - **优点**：
        - **地址空间分离**：避免了与内存地址的冲突，更适用于地址空间受限的系统。
        - **精确控制**：允许更细粒度的控制和硬件级的优化。
    - **应用场景**：常见于传统的 PC 架构，适用于不需要频繁或大量数据交换的设备。

### 3.5. 流控制

流控制确保数据在不同速度的设备和系统之间正确同步，包括调整数据传输速度、管理缓冲区和处理能力的不匹配。
- 3.5.1. 调整数据发送速度
    - **发送方速度调整**：流控制机制可以动态调整发送方的数据发送速度，以匹配接收方的处理能力。
    - **反馈机制**：接收方根据其处理能力和缓冲区状态，通过特定信号（如控制字符或硬件信号）向发送方反馈，指示其增加、减少或暂停数据传输。

- 3.5.2. 缓冲区管理
    - **接收缓冲区**：接收方通常有一个缓冲区来暂存接收到的数据。当缓冲区接近满时，流控制机制会通知发送方减慢发送速度或暂停发送。
    - **溢出预防**：通过监控缓冲区状态，流控制有助于防止缓冲区溢出，这在数据传输速度远高于处理速度的场景中尤其重要。

+ 3.5.3. 网络条件适应性
    + **网络拥塞控制**：在网络通信中，流控制还涉及到根据网络的拥塞状态调整数据流量，以避免网络过载。
    + **数据包延迟和丢失**：流控制机制可减少由于网络延迟或丢包导致的重传，提高网络效率。

+ 3.5.4. 错误处理和恢复
    - **错误检测**：流控制机制通常与错误检测机制结合使用，以确保数据的完整性和正确性。
    - **重传机制**：在检测到错误或丢失的数据包时，流控制机制可协助实现有效的数据重传。

+ 3.5.5. 协议支持
    - **协议实现**：许多通信和网络协议（如 TCP）内置了复杂的流控制机制，以适应各种数据传输和网络环境。

## 4. 逻辑门

### 4.1. 逻辑门

- **基本门**：与门（AND）、或门（OR）、非门（NOT）是最基本的数字逻辑门，用于执行简单的逻辑运算。
- **组合门**：如与非门（NAND）、或非门（NOR）、异或门（XOR）和同或门（XNOR），它们是基本逻辑门的扩展，用于执行更复杂的逻辑运算。

### 4.2. 用逻辑门构建复杂电路

- **加法器**：如半加器和全加器，它们使用基本的逻辑门来执行二进制数的加法运算。
- **多路复用器和解复用器**：用于数据选择和路由。
- **寄存器**：使用触发器构建，用于存储数据。
- **计数器**：基于触发器，用于计数和计时操作。

## 5. 组合逻辑和时序逻辑

### 5.1. 组合逻辑

- **定义**：组合逻辑电路的输出仅取决于当前的输入状态，而与之前的状态无关。
- **特点**：无记忆功能，输出直接响应输入变化。
- **示例**：逻辑门电路、加法器等。

### 5.2. 时序逻辑

- **定义**：时序逻辑电路的输出不仅取决于当前的输入，还取决于历史输入（即电路的前一状态）。
- **特点**：具有记忆功能，可以存储信息。
- **核心组件**：触发器（如D触发器、JK触发器），是构建复杂时序逻辑电路的基础。
- **示例**：寄存器、计数器、顺序控制电路。

### 5.3. CPU 的核心组件

- **算术逻辑单元（ALU）**：负责执行所有的算术和逻辑运算。
- **控制单元**：解释程序指令并控制其他部件。
- **寄存器组**：存储操作数、指令和中间结果。
- **数据路径**：连接上述各个组件，用于数据传输。

## 6. 汇编语言和机器语言

### 6.1. 机器语言

机器语言是计算机的最底层语言，由二进制代码组成，直接被 CPU 执行。

- **直接执行**：机器语言由 CPU 直接解释和执行，不需要转换或编译。
- **硬件依赖性**：机器语言是针对特定硬件或处理器架构设计的，因此它是平台相关的。

### 6.2. 汇编语言

汇编语言是一种低级编程语言，它通过符号化的表示方法（助记符）来表达机器语言指令。

- **人类可读**：虽然仍然较为底层，但汇编语言相比于机器语言对人类更易读和理解。
- **需要汇编器**：将汇编语言代码转换成机器语言的过程需要一个叫做汇编器（Assembler）的程序。

### 6.3. CPU 如何解释和执行指令

1. **指令获取**：CPU 从内存中获取指令，这些指令可以是机器语言形式的二进制代码。
2. **指令解码**：CPU 的控制单元解码这些指令，确定要执行的操作和操作数。
3. **执行指令**：CPU 的算术逻辑单元（ALU）或其他组件执行指令，进行计算或数据操作。
4. **结果存储**：执行结果可能被存储回内存或保留在 CPU 寄存器中。

### 6.4. 从高级语言到机器码

- **编译过程**：高级语言（如 C++、Java）编写的程序需要通过编译器转换为机器语言。编译器将高级语言代码编译成汇编语言，然后再由汇编器转换为机器码。
- **优化**：现代编译器在将高级语言转换为机器码的过程中会进行优化，以提高代码的执行效率和减少资源消耗。

## 7. 指令集架构（ISA）

指令集架构（Instruction Set Architecture，ISA）是定义 CPU 操作和程序控制计算机硬件方式的一套规则和标准。它涉及到 CPU
可以执行的所有指令，包括数据处理、数据存储、数据检索、逻辑操作和控制操作等。

### 7.1. 复杂指令集计算机（CISC）

- **特点**：CISC 架构的 CPU 拥有大量指令，包括许多专用和复杂的指令。这些指令可以执行高级的操作，通常在单个指令周期内完成多个低级操作。
- **优点**：更高的指令密度，减少程序代码的大小，通常与高级编程语言更紧密地集成。
- **缺点**：硬件实现更复杂，指令的解码和执行可能更耗时。
- **例子**：**Intel x86 和 x86-64**：这是最著名的 CISC 架构之一，被广泛用于个人电脑、服务器和工作站。

### 7.2. 精简指令集计算机（RISC）

- **特点**：RISC 架构的 CPU 指令集较小，指令通常很简单，可以在一个指令周期内快速执行。
- **优点**：硬件实现简化，提高了指令的执行速度和处理器的效率。
- **缺点**：可能需要更多的指令来执行复杂操作，导致程序代码增大。
- **例子**：
    - **ARM 架构**：ARM 处理器是 RISC 架构的典型代表，被广泛用于智能手机、平板电脑和嵌入式系统。例如，Apple 的 A 系列芯片（如
      A14 Bionic）、高通的 Snapdragon 系列和三星的 Exynos 系列都基于 ARM 架构。
    - **RISC-V**：RISC-V 是一种开源的 RISC 指令集架构，越来越多地被用于各种领域，包括嵌入式系统、服务器和高性能计算。

### 7.3. 显式并行指令计算（EPIC）

- **特点**：EPIC 架构旨在通过软件来增加并行操作，以提高性能。
- **优点**：可以高效地利用多个处理器核心，提高并行处理的能力。
- **缺点**：编译器的设计和优化更为复杂。
- **例子**：**Intel Itanium**：最著名的 EPIC 架构实现。Itanium 是由 Intel 和惠普共同开发的，主要针对企业级服务器和高性能计算市场。Itanium
  架构特别强调软件在提高指令级并行性（Instruction-Level Parallelism，ILP）方面的作用，试图通过编译器优化来显式地指示并行执行的指令。
- **现状**：由于软件兼容性和编译器优化复杂性，在通用计算机市场上的成功有限。

### 7.4. 长指令字（VLIW）

- **特点**：VLIW 架构允许在单个长指令字中封装多个操作。
- **优点**：可以在单个时钟周期内执行多个操作，提高并行性。
- **缺点**：编码效率较低，对编译器的优化要求高。
- **现状**：VLIW 架构在数字信号处理器领域仍然广泛使用，特别是在需要处理大量并行操作的应用中，如音频、视频和通信处理。

### 7.5. 指令集的影响

- **性能**：不同的指令集对 CPU 的性能有重大影响，包括执行速度、能效和处理能力。
- **设计**：指令集影响 CPU 的设计，包括硬件的复杂度、制造成本和功耗。
- **软件兼容性**：指令集决定了软件和操作系统的兼容性。不同指令集的 CPU 通常无法运行为其他架构编写的软件。

### 7.6. 比较 Intel 和 ARM 芯片的功耗

| 特性/架构      | ARM（精简指令集计算机，RISC） | Intel（复杂指令集计算机，CISC） |
|------------|--------------------|----------------------|
| **指令集类型**  | 精简指令集（RISC）        | 复杂指令集（CISC）          |
| **设计重点**   | 高能效、低功耗            | 高性能计算                |
| **功耗**     | 一般较低，适合电池供电的移动设备   | 相对较高，适合连接电源的桌面和服务器   |
| **处理效率**   | 单个指令通常在一个时钟周期内完成   | 单个指令可能需要多个时钟周期完成     |
| **主要应用**   | 智能手机、平板电脑、嵌入式系统    | 个人电脑、服务器、工作站         |
| **电源管理**   | 高效电源管理，动态调节功耗      | 高性能，热设计功率（TDP）较高     |
| **历史和兼容性** | 相对较新，专注于移动和嵌入式市场   | 长期向后兼容，重点在桌面和服务器市场   |

## 8. 处理器核心和多核处理

处理器核心是 CPU 中的一个独立处理单元，负责执行计算任务。每个核心可以独立执行指令和处理数据。

### 8.1. 单核 CPU

- **工作原理**：单核 CPU 只有一个处理器核心，负责所有的计算任务。
- **特点**：适用于处理能力要求不高的应用。在多任务处理中，任务需要排队执行，可能导致性能瓶颈。

### 8.2. 多核 CPU

- **工作原理**：多核 CPU 包含多个处理器核心，每个核心可以独立执行任务。
- **特点**：提高了处理能力和效率，尤其是在并行处理和多任务处理方面。可以更有效地运行多线程和多进程程序。有助于节能和减少热量产生，因为分散了计算任务，每个核心的负载减少。

### 8.3. 一些关键点

- **并行处理**：多核处理器能够同时执行多个任务，从而提高整体性能。
- **热效率**：多核处理器可以在较低的频率下运行，分散热量产生，提高能效。
- **应用优化**：要充分利用多核处理器的性能，软件和应用程序需要进行优化，以支持并行处理和多线程。
- **核心间通信**：在多核处理器中，核心间的通信对性能有重要影响。高效的缓存一致性和内存管理对于优化性能至关重要。
- **缩放性能**：并非所有任务都能从多核处理中受益，一些串行任务或者对并行性优化不足的程序可能无法充分利用多核处理器的优势。

### 8.4. 阿姆达尔定律

- 评估并行计算性能提升的重要工具，它说明了程序并行化的潜在效益，以及由于串行部分导致的性能限制。

- 加速比
  $$
  S = \frac{1}{(1-P) + \frac{P}{N}}
  $$

    - $S$ 是总体加速比。
    - $P$ 是程序中可以并行化的部分比例（介于 0 和 1 之间）。
    - $N$ 是处理器的数量。

- 阿姆达尔定律指出，程序的加速比受到其串行部分的限制。即使并行部分得到了显著加速，整个程序的加速比也受到无法并行化的串行部分的制约。

### 8.5. 无法充分利用多核处理器的任务示例

- 单线程应用程序： 例如某些老旧的桌面应用程序，它们可能完全没有为多线程或多核处理优化。
- 依赖顺序执行的算法： 诸如某些加密算法或文件压缩算法，它们的操作顺序通常很难打破。

### 8.6. 自动并行优化的编译技术示例

- 循环并行化： 许多现代编译器，如 GCC 或 LLVM，可以自动识别并并行化某些类型的循环结构。
- 数据并行编程模型： OpenMP（用于 C/C++ 和 Fortran）和 Intel Threading Building Blocks 等技术可以在编译时对并行部分进行优化。

## 9. 总线和接口

在计算机系统中，总线是连接各种硬件组件并实现数据传输的关键部分。主要的总线类型包括数据总线、地址总线和控制总线。

### 9.1. 数据总线（Data Bus）

- **作用**：数据总线负责在计算机的各个部件之间传输实际的数据。
- **特点**：宽度决定了可以一次传输的数据量。例如，32位宽的数据总线一次可以传输32位数据。连接 CPU、内存、I/O 设备等。

### 9.2. 地址总线（Address Bus）

- **作用**：地址总线用于指定数据在内存中的存储位置或要与之通信的特定 I/O 设备。
- **特点**：宽度决定了 CPU 可以访问的内存地址范围。例如，20位宽的地址总线能够寻址 220220 个不同的地址。仅用于传送地址信息，不传输实际的数据。

### 9.3. 控制总线（Control Bus）

- **作用**：控制总线用于传输控制信号，这些信号协调和管理计算机中各个部件的活动。
- **特点**：包括各种控制信号，如读/写指令、中断请求、时钟信号等。确保数据和地址总线上的数据能够在适当的时间以适当的方式被传输和接收。